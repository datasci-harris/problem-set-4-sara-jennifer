---
title: "DAP II Problem Set 4"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 
We use (`*`) to indicate a problem that we think might be time consuming. 
    
## Style Points (10 pts) 
Please refer to the minilesson on code style
**[here](https://uchicago.zoom.us/rec/share/pG_wQ-pHTQrJTmqNn4rcrw5V194M2H2s-2jdy8oVhWHkd_yZt9o162IWurpA-fxU.BIQlSgZLRYctvzp-)**.

## Submission Steps (10 pts)
1. This problem set is a paired problem set.
2. Play paper, scissors, rock to determine who goes first. Call that person *Partner 1*.
    - Partner 1 (name and cnet ID): Sara Van Valkenburgh, 12415386
    - Partner 2 (name and cnet ID):
3. Partner 1 will accept the `ps4` and then share the link it creates with their partner. You can only share it with one partner so you will not be able to change it after your partner has accepted. 
4. "This submission is our work alone and complies with the 30538 integrity policy." Add your initials to indicate your agreement: \*\*sv\*\* \*\*JE\*\*
5. "I have uploaded the names of anyone else other than my partner and I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  (1 point)
6. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*
7. Knit your `ps4.qmd` to an PDF file to make `ps4.pdf`, 
    * The PDF should not be more than 25 pages. Use `head()` and re-size figures when appropriate. 
8. (Partner 1): push  `ps4.qmd` and `ps4.pdf` to your github repo.
9. (Partner 1): submit `ps4.pdf` via Gradescope. Add your partner on Gradescope.
10. (Partner 1): tag your submission in Gradescope

**Important:** Repositories are for tracking code. **Do not commit the data or shapefiles to your repo.** The best way to do this is with `.gitignore`, which we have covered in class. If you do accidentally commit the data, Github has a [guide](https://docs.github.com/en/repositories/working-with-files/managing-large-files/about-large-files-on-github#removing-files-from-a-repositorys-history). The best course of action depends on whether you have pushed yet. This also means that both partners will have to download the initial raw data and any data cleaning code will need to be re-run on both partners' computers. 

## Download and explore the Provider of Services (POS) file (10 pts)

<<<<<<< Updated upstream
1. Variables pulled:
=======
1. 
Variables pulled:
>>>>>>> Stashed changes

* PRVDR_CTGRY_SBTYP_CD - Identifies the subtype of the provider, within the primary category
* PRVDR_CTGRY_CD -  Identifies the type of provider participating in the Medicare/Medicaid program
* FAC_NAME - Facility name
* PRVDR_NUM - Unique CMS certification number
* PGM_TRMNTN_CD -  Indicates the current termination status for the provider (termination code)
* ZIP_CD - Zip code

2. 
```{python}
import pandas as pd

# read in the data for Q4 2016
filepath = "data/pos2016.csv"
data_2016 = pd.read_csv(filepath)

```

```{python}
# Make sure the codes are in the right format -- 01
data_2016['PRVDR_CTGRY_CD'] = data_2016['PRVDR_CTGRY_CD'].apply(
    lambda x: f"{int(float(x)):02}" if pd.notna(x) else x)
data_2016['PRVDR_CTGRY_SBTYP_CD'] = data_2016['PRVDR_CTGRY_SBTYP_CD'].apply(
    lambda x: f"{int(float(x)):02}" if pd.notna(x) else x)

# subset to provider type code 01 and subtype code 01
short_term_hospitals = data_2016[(data_2016['PRVDR_CTGRY_CD'] == '01') & (
    data_2016['PRVDR_CTGRY_SBTYP_CD'] == '01')]

short_term_hospitals['PRVDR_NUM'].unique
```

    a. We know from the data dictionary that each hospital has a unique CMS certification number, which is listed under PRVDR_NUM. There are 7245 unique CMS numbers in this 2016 dataset, indicating that there are 7245 hospitals that fit these categories.

    b. According to "Definitive Healthcare" https://www.definitivehc.com/blog/how-many-hospitals-are-in-the-us, there are 3,873 short-term accute hospitals in the United States as of April 2024, which is a much smaller number than the one in our data set. It could be that many hospitals have merged or closed since 2016. According to "Statista" https://www.statista.com/statistics/185843/number-of-all-hospitals-in-the-us/, there were 5534 hospitals in the US in 2016. This is also smaller than the number in our data set, even though the data was from the same year. It could be that hospitals are coded differently in different data sets, or this dataset might exclude or include additional facilities not in other counts.

3. 
```{python}
import os

# read in other data sets
data_2017 = pd.read_csv('data/pos2017.csv')
data_2018 = pd.read_csv('data/pos2018.csv', encoding='latin1')
data_2019 = pd.read_csv('data/pos2019.csv', encoding='latin1')

# get rid of strange symbol in the column name
data_2018.rename(
    columns={'ï»¿PRVDR_CTGRY_SBTYP_CD': 'PRVDR_CTGRY_SBTYP_CD'}, inplace=True)


```

```{python}
# Function to make sure that codes in each dataset are in 01 format

def format_provider_codes(data):

    for column in ['PRVDR_CTGRY_CD', 'PRVDR_CTGRY_SBTYP_CD']:
        data[column] = data[column].apply(
            lambda x: f"{int(float(x)):02}" if pd.notna(x) else x
        )
    return data

data_2017 = format_provider_codes(data_2017)
data_2018 = format_provider_codes(data_2018)
data_2019 = format_provider_codes(data_2019)

# add a year column to each df
data_2016['year'] = 2016
data_2017['year'] = 2017
data_2018['year'] = 2018
data_2019['year'] = 2019
```

```{python}
# subset data for each year
short_term_hospitals_2017 = data_2017[
    (data_2017['PRVDR_CTGRY_CD'] == '01') &
    (data_2017['PRVDR_CTGRY_SBTYP_CD'] == '01')
]

short_term_hospitals_2018 = data_2018[
    (data_2018['PRVDR_CTGRY_CD'] == '01') &
    (data_2018['PRVDR_CTGRY_SBTYP_CD'] == '01')
]

short_term_hospitals_2019 = data_2019[
    (data_2019['PRVDR_CTGRY_CD'] == '01') &
    (data_2019['PRVDR_CTGRY_SBTYP_CD'] == '01')
]

# combine all four datasets
data = pd.concat(
    [short_term_hospitals, short_term_hospitals_2017,
        short_term_hospitals_2018, short_term_hospitals_2019],
    ignore_index=True
) 
```

```{python}
import altair as alt

# Count the observations by year
observations_by_year = data.groupby('year').size().reset_index(name='count')

# Create a bar chart
alt.Chart(observations_by_year).mark_bar(color='hotpink').encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('count:Q', title='Number of Observations')
).properties(
    title='Number of Observations by Year',
    width=400,
    height=300
) + alt.Chart(observations_by_year).mark_text(
    align='center',
    baseline='bottom',
    dy=-5
).encode(
    text='count:Q'
)
```

4. 
a.
```{python}

# Count the number of unique hospitals by year
unique_hospitals = data.groupby(
    'year')['PRVDR_NUM'].nunique().reset_index(name='unique_hospitals')

# Create a bar chart for unique hospitals and add text labels
alt.Chart(unique_hospitals).mark_bar(color='green').encode(
    x=alt.X('year:O', title='Year'),
    y=alt.Y('unique_hospitals:Q', title='Number of Unique Hospitals')
).properties(
    title='Number of Unique Hospitals by Year',
    width=400,
    height=300
) + alt.Chart(unique_hospitals).mark_text(
    align='center',
    baseline='bottom',
    dy=-5
).encode(
    text='unique_hospitals:Q'
)
```

    b. The two plots are exactly the same, which tells us that there is one hospital per row of our data set.

## Identify hospital closures in POS file (15 pts) (*)

1. 
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 
    a.
    b. 
2. 

## Calculate zip code’s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
